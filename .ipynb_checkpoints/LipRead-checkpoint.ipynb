{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b331d8bc-909d-4b74-b5f4-e530b34f7345",
   "metadata": {},
   "source": [
    "#### **Lip Reading Application**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e45e6-821a-4f68-832e-979f2cff351b",
   "metadata": {},
   "source": [
    "##### Install/Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b1627-8b8b-4202-bf2b-abd0f817af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Install dependencies and confirm installation with !pip list\n",
    "!pip install opencv-python matplotlib imageio gdown tensorflow-macos\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e33e7-957c-47f2-a5b2-87959273b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import os\n",
    "import cv2\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import gdown\n",
    "\n",
    "#Neural Network dependencies\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9be66e-352f-4147-b7bd-38dc8319d452",
   "metadata": {},
   "source": [
    "##### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef203f-8189-42c7-922d-0a408f81b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# #Downloading dataset that was made for creating lip-read models \n",
    "# UNCOMMENT FOR FIRST RUN\n",
    "# url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "# output = 'data.zip'\n",
    "# gdown.download(url, output, quiet = False)\n",
    "# gdown.extractall('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d10412-6716-467b-a26b-d354d94eb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path) -> List[float]:\n",
    "    '''\n",
    "    Takes in a path to a video and returns the float values for each frame\n",
    "        Args: \n",
    "            path: str --> path to video that will be passed into model\n",
    "        Returns:\n",
    "            List of floats that represents video1\n",
    "    '''\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames=[]\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        success, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        #isolates the mouth --> we can also use a lip detector to isolate the mouth\n",
    "        frames.append(frame[190:236,80:220,:])\n",
    "    cap.release()\n",
    "    \n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames-mean), tf.float32)/std                 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb88359-bce7-4e62-9db6-d57ba26312c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c999f2f-e42e-491b-9b6d-3daecb21602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocab is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '](size=40)\n"
     ]
    }
   ],
   "source": [
    "char_num = tf.keras.layers.StringLookup(vocabulary = vocab, oov_token=\"\")\n",
    "num_char = tf.keras.layers.StringLookup(vocabulary = char_num.get_vocabulary(), oov_token=\"\", invert = True)\n",
    "print(f'The vocab is: {char_num.get_vocabulary()}'\n",
    "      f'(size={char_num.vocabulary_size()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a52e8-a041-4520-8835-d87ed3924f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignments(path) -> List[str]:\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2]!='sil':\n",
    "            tokens=[*tokens,' ', line[2]]\n",
    "    return char_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef329734-0765-48a9-9dde-dbc6b48b94cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    path = bytes.decode(path.numpy())\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data','alignments', 's1',f'{file_name}.align')\n",
    "    frames = load_video(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b8b76-e12b-4f65-975c-0a5ac8510bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappable_function(path) -> List[str]:\n",
    "    return tf.py_function(load_data,[path], (tf.float32,tf.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e7e2b-1c97-4839-a5aa-bb4d291604ed",
   "metadata": {},
   "source": [
    "##### Tensorflow Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93d955-86e6-4e0c-9c99-380e6c4d00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
    "data = data.shuffle(500)\n",
    "data = data.map(mappable_function)\n",
    "#batching into groups of 2, padding 75 frames with 40 tokens\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6337c1-3af2-4b7f-9585-98580786ad10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[19,  5, 20, 39, 18,  5,  4, 39,  2, 25, 39, 21, 39, 14,  9, 14,\n",
       "          5, 39,  1,  7,  1,  9, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [12,  1, 25, 39, 18,  5,  4, 39, 23,  9, 20,  8, 39, 19, 39, 26,\n",
       "          5, 18, 15, 39, 16, 12,  5,  1, 19,  5,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the data is now in batches of 2 alignments and 2 frames\n",
    "frames, alignments = data.as_numpy_iterator().next()\n",
    "alignments, len(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953dc5e-8d81-4a51-a6d8-e4e4e5103f1c",
   "metadata": {},
   "source": [
    "##### Tensorflow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f171f3-dc9e-4519-8f39-e0ca5b87c46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:21:00.440034: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-18 15:21:00.441084: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-18 15:21:00.441723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-18 15:21:00.516320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-18 15:21:00.540342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-18 15:21:00.540994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-18 15:21:00.541575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-18 15:21:00.676104: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-18 15:21:00.677103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-18 15:21:00.677740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-18 15:21:00.752856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-18 15:21:00.776216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-18 15:21:00.776857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-18 15:21:00.777458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv3D(128,3,input_shape=(75,46,140,1),padding='same',activation='relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256,3,padding='same',activation='relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75,3,padding='same',activation='relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(char_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2b937-6e12-460d-ae1f-400f3230713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_50 (Conv3D)          (None, 75, 46, 140, 128)  3584      \n",
      "                                                                 \n",
      " max_pooling3d_50 (MaxPoolin  (None, 75, 23, 70, 128)  0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_51 (Conv3D)          (None, 75, 23, 70, 256)   884992    \n",
      "                                                                 \n",
      " max_pooling3d_51 (MaxPoolin  (None, 75, 11, 35, 256)  0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_52 (Conv3D)          (None, 75, 11, 35, 75)    518475    \n",
      "                                                                 \n",
      " max_pooling3d_52 (MaxPoolin  (None, 75, 5, 17, 75)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed_15 (TimeDi  (None, 75, 6375)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_30 (Bidirecti  (None, 75, 256)          6660096   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 75, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_31 (Bidirecti  (None, 75, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 75, 256)           0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 75, 41)            10537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,471,924\n",
      "Trainable params: 8,471,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c1bdb-ab28-4bb1-a81d-b414daa94e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.02289667, 0.02361521, 0.02488543, ..., 0.0276392 ,\n",
       "         0.01984844, 0.02383464],\n",
       "        [0.02218219, 0.02346753, 0.02441526, ..., 0.02791576,\n",
       "         0.01969178, 0.02348711],\n",
       "        [0.02165942, 0.02334739, 0.02352175, ..., 0.02846433,\n",
       "         0.01952133, 0.02338246],\n",
       "        ...,\n",
       "        [0.02074331, 0.02085769, 0.01731861, ..., 0.02948437,\n",
       "         0.01839092, 0.02197212],\n",
       "        [0.02120205, 0.02090364, 0.01751425, ..., 0.02872388,\n",
       "         0.01903566, 0.02199452],\n",
       "        [0.02171118, 0.02099093, 0.01798891, ..., 0.0277431 ,\n",
       "         0.01958937, 0.0223166 ]],\n",
       "\n",
       "       [[0.0223127 , 0.02238715, 0.02306183, ..., 0.02518002,\n",
       "         0.01944063, 0.02421109],\n",
       "        [0.02208225, 0.02214982, 0.0228009 , ..., 0.02528704,\n",
       "         0.01898592, 0.02399273],\n",
       "        [0.02189158, 0.02182242, 0.02237349, ..., 0.02540128,\n",
       "         0.01873199, 0.02405256],\n",
       "        ...,\n",
       "        [0.02155303, 0.02226604, 0.01852947, ..., 0.02656786,\n",
       "         0.01912714, 0.02214107],\n",
       "        [0.02188152, 0.02235916, 0.01900699, ..., 0.02618125,\n",
       "         0.01972817, 0.0220863 ],\n",
       "        [0.02235   , 0.02249897, 0.01963217, ..., 0.02572843,\n",
       "         0.02031952, 0.02242147]]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check what our model returns\n",
    "yhat = model.predict(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f6935-8c16-4b1c-b036-a41bb9e600c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqffffffff'>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction by the model before training\n",
    "tf.strings.reduce_join([num_char(tf.argmax(x)) for x in yhat[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
